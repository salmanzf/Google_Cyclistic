# -*- coding: utf-8 -*-
"""Cyclistic_Monthly.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dOMGlzzOLXQvQafCSz2IG4fBs7PSw1Bq
"""

pip install --upgrade matplotlib

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Data Preparation"""

from pickle import NONE
pd.set_option('max_row', None)

jan = pd.read_csv('/content/drive/MyDrive/Portfolio_Cycle/202201-divvy-tripdata.csv')
jan.head()

jan.dtypes

jan['started_at'] = pd.to_datetime(jan['started_at'])
jan['ended_at'] = pd.to_datetime(jan['ended_at'])

jan['duration'] = jan['ended_at']-jan['started_at']
jan['duration'].head()

jan.head()

jan.isnull().sum()

#Check duplicate
jan.duplicated(subset=['ride_id']).sum()

"""## Start Long-Lat NULL Variable"""

jan[jan['start_station_id'].isna()].reset_index(drop=True).head()

#assign null
jan_null = jan[jan['start_station_id'].isna()].reset_index(drop=True)

jan_null.isna().sum()

"""## End Long-Lat NULL Variable"""

jan[jan['end_station_id'].isna()].head()

#assign null variable
jan_null_end = jan[jan['end_station_id'].isna()].reset_index(drop=True)

jan_null_end.isna().sum()

"""##Start Long-Lat Reference Variable"""

#Kolom referensi
jan_ref = jan.groupby(by=['start_station_id']).median().reset_index()
jan_ref.head()

jan_ref[jan_ref.duplicated(subset=['start_lat', 'start_lng'])]

jan_ref[(jan_ref['start_lat']==41.657074332) &  (jan_ref['start_lng']==-87.598875642)]

"""## End Long-Lat Reference Variable"""

jan_ref_end = jan.groupby(by=['end_station_id']).median().reset_index()
jan_ref_end.head(5)

"""## Loop to Reference Variable"""

#Search the nearest number FUNCTION
def find_nearest(array, value):
    array = np.asarray(array)
    idx = (np.abs(array - value)).argmin()
    return array[idx]

find_nearest(jan_ref['start_lat'], 41.95)

z=[]
q=[]
#START Long-Lat Loop Section
for i, x in enumerate(jan_null['start_lat']):
  z.append(x)
  new_lat = find_nearest(jan_ref['start_lat'], x)
  jan_null.iloc[i, 8] = new_lat
  ref_jan = jan_ref.loc[jan_ref['start_lat']==new_lat, 'start_lng'].reset_index(drop=True)
  #ref_null = jan_null.loc[jan_null['start_lat']==new_lat, 'start_lng']
  j=i
  new_long = find_nearest(ref_jan, jan_null.iloc[i, 9])
  jan_null.iloc[i, 9] = new_long
  q.append(j)
  jan_null.iloc[i, 5] = jan_ref.loc[(jan_ref['start_lat']==new_lat) & (jan_ref['start_lng']==new_long), 'start_station_id'].values[0]

#END Long-Lat Loop Section
for i, x in enumerate(jan_null_end['end_lat']):
  z.append(x)
  new_end_lat = find_nearest(jan_ref_end['end_lat'], x)
  jan_null_end.iloc[i, 10] = new_end_lat
  ref_jan = jan_ref_end.loc[jan_ref_end['end_lat']==new_end_lat, 'end_lng'].reset_index(drop=True)
  #ref_null = jan_null.loc[jan_null['start_lat']==new_lat, 'start_lng']
  j=i
  new_end_long = find_nearest(ref_jan, jan_null_end.iloc[i, 11])
  jan_null_end.iloc[i, 11] = new_end_long
  q.append(j)
  jan_null_end.iloc[i, 7] = jan_ref_end.loc[(jan_ref_end['end_lat']==new_end_lat) & (jan_ref_end['end_lng']==new_end_long), 'end_station_id'].values[0]

jan_null.head(5)

jan_null_end.head(5)

#Loop Station Name
qw=[]
for i, x in enumerate(jan_null['start_station_id']):
  qw.append(x)
  jan_null.iloc[i, 4] = jan.loc[jan['start_station_id']==x, 'start_station_name'].values[0]

#Loop Station ID
qw=[]
for i, x in enumerate(jan_null_end['end_station_id']):
  qw.append(x)
  jan_null_end.iloc[i, 6] = jan.loc[jan['end_station_id']==x, 'end_station_name'].values[0]

jan_null.head(5)

jan_null_end.head(5)

jan_null.isna().sum()

jan_null_end.isna().sum()

jan[jan['start_station_name'].isna()].isna().sum()

"""## Loop to Main Variable"""

qw=[]
#Joining two table for start_station
for i, x in enumerate(jan['ride_id']):
  if pd.isna(jan['start_station_name'].iloc[i]):
    
    jan.iloc[i,4] = jan_null.loc[jan_null['ride_id']==x, 'start_station_name'].values[0]
    jan.iloc[i,5] = jan_null.loc[jan_null['ride_id']==x, 'start_station_id'].values[0]
  else:
    qw.append(i)
    continue

#Joining two table for end_station
for i, x in enumerate(jan['ride_id']):
  if pd.isna(jan['end_station_name'].iloc[i]):
    
    jan.iloc[i,6] = jan_null_end.loc[jan_null_end['ride_id']==x, 'end_station_name'].values[0]
    jan.iloc[i,7] = jan_null_end.loc[jan_null_end['ride_id']==x, 'end_station_id'].values[0]
  else:
    qw.append(i)
    continue

jan.isna().sum()

jan.head()

"""## Drop Final NULL Values"""

jan.shape

jan.dropna(inplace=True)

jan.isna().sum()

jan.shape

jan.to_csv('/content/drive/MyDrive/Portfolio_Cycle/jan_final.csv', index=False)

"""# Data Exploration"""

jan22 = pd.read_csv('/content/drive/MyDrive/Portfolio_Cycle/jan_final.csv')
jan22.head()

jan22.isna().sum()

jan22['started_at'] = pd.to_datetime(jan22['started_at'])
jan22['ended_at'] = pd.to_datetime(jan22['ended_at'])

for i, x in enumerate(jan22['ride_id']):
  jan22['duration'].iloc[i] = (jan22['ended_at'].iloc[i]-jan22['started_at'].iloc[i]).total_seconds()

jan22['duration'] = jan22['duration'].astype(int)

jan22.dtypes

"""## Rideable Type"""

sns.countplot(x='rideable_type', data=jan22)
plt.show()

"""- slight difference between electric and classic, and not enough interest for docked bike"""

sns.barplot(x='rideable_type', y='duration', data=jan22, estimator=sum, ci=None)

sns.barplot(x='rideable_type', y='duration', estimator=np.median, data=jan22, ci=None)

"""- classic bike still dominates total duration (seconds)
- despite the low usage, most of the docked bike user has a much longer duration per user than electric bike and classic bike

### Type Specific Time

#### Day Sum
"""

sns.barplot(x=jan22['started_at'].dt.day, y='duration', data=jan22[jan22['rideable_type']=='electric_bike'], estimator=sum, ci=None)

sns.barplot(x=jan22['started_at'].dt.day, y='duration', data=jan22[jan22['rideable_type']=='classic_bike'], estimator=sum, ci=None)

sns.barplot(x=jan22['started_at'].dt.day, y='duration', data=jan22[jan22['rideable_type']=='docked_bike'], estimator=sum, ci=None)

"""- electric bike and classic bike has similar distribution
- docked bike has abnormal behaviour pattern

#### Day MEDIAN
"""

sns.barplot(x=jan22['started_at'].dt.day, y='duration', data=jan22[jan22['rideable_type']=='electric_bike'], estimator=np.median, ci=None)

sns.barplot(x=jan22['started_at'].dt.day, y='duration', data=jan22[jan22['rideable_type']=='classic_bike'], estimator=np.median, ci=None)

sns.barplot(x=jan22['started_at'].dt.day, y='duration', data=jan22[jan22['rideable_type']=='docked_bike'], estimator=np.median, ci=None)

"""#### Time SUM"""

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', data=jan22[jan22['rideable_type']=='electric_bike'], estimator=sum, ci=None)

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', data=jan22[jan22['rideable_type']=='classic_bike'], estimator=sum, ci=None)

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', data=jan22[jan22['rideable_type']=='docked_bike'], estimator=sum, ci=None)

"""- docked has abnormal pattern

#### Time MEDIAN
"""

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', data=jan22[jan22['rideable_type']=='electric_bike'], estimator=np.median, ci=None)

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', data=jan22[jan22['rideable_type']=='classic_bike'], estimator=np.median, ci=None)

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', data=jan22[jan22['rideable_type']=='docked_bike'], estimator=np.median, ci=None)

"""## Member or Casual

### Member Type
"""

sns.countplot(x='member_casual', data=jan22)
plt.show()

"""- most of the user is registered as member"""

sns.countplot(x='rideable_type', hue='member_casual', data=jan22)
plt.show()

"""- docked bike doesnt have member user, it might reserved for casual user (?)"""

sns.barplot(x='member_casual', y='duration', data=jan22, estimator=sum, ci=None)

sns.barplot(x='member_casual', y='duration', estimator=np.median, data=jan22, ci=None)

sns.barplot(x='rideable_type', y='duration', hue='member_casual', data=jan22, estimator=sum, ci=None)

sns.barplot(x='rideable_type', y='duration', hue='member_casual', estimator=np.median, data=jan22, ci=None)

"""- member use more duration on the trip overall
- per casual user overall has more duration than per member user (especially docked bike user)

### Member Specific Time

#### Day SUM
"""

sns.barplot(x=jan22['started_at'].dt.day, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='member'], ci=None)

sns.barplot(x=jan22['started_at'].dt.day, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='casual'], ci=None)

"""#### Day MEDIAN"""

sns.barplot(x=jan22['started_at'].dt.day, y='duration', estimator=np.median, data=jan22[jan22['member_casual']=='member'], ci=None)

sns.barplot(x=jan22['started_at'].dt.day, y='duration', estimator=np.median, data=jan22[jan22['member_casual']=='casual'], ci=None)

"""#### Day of The Week SUM"""

sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='member'], ci=None)

sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='casual'], ci=None)

"""- Most of the member users are working force or student because most of the users are at Monday-Friday (0-4)

#### Day of The Week MEDIAN
"""

sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=np.median, data=jan22[jan22['member_casual']=='member'], ci=None)

sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=np.median, data=jan22[jan22['member_casual']=='casual'], ci=None)

"""- Since most of the member only use for daily activity (working, school, commute) it has lower median value than casual user throughout the week
- Casual user has more median value, especially at Saturday & Sunday (5-6) which is the weekend. It is suspected most of the casual user uses this service for sightseing and not for daily necessities.

#### Time SUM
"""

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='member'], ci=None)

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='casual'], ci=None)

#Casual but without docked bike
sns.barplot(x=jan22['started_at'].dt.hour, y='duration', estimator=sum, data=jan22[(jan22['member_casual']=='casual')
& (jan22['rideable_type']!='docked_bike')], ci=None)

"""- docked_bike in casual user causes irregularity (sharper peak-valley)
- mostly has the same pattern between member and casual (without dokcked_bike)

#### Time MEDIAN
"""

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', estimator=np.median, data=jan22[jan22['member_casual']=='member'], ci=None)

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', estimator=np.median, data=jan22[jan22['member_casual']=='casual'], ci=None)

#Casual but without docked bike
sns.barplot(x=jan22['started_at'].dt.hour, y='duration', estimator=np.median, data=jan22[(jan22['member_casual']=='casual')
& (jan22['rideable_type']!='docked_bike')], ci=None)

"""- Median didnt really affected by the outlier since it only choose the middle number

## Specific Time

### Which days
"""

sns.countplot(x=jan22['started_at'].dt.day, data=jan22)

"""- theres no specific distribution regarding frequency due to days
- roughly more people using bike service during middle of the month
"""

sns.barplot(x=jan22['started_at'].dt.day, y='duration', data=jan22, estimator=sum, ci=None)

sns.barplot(x=jan22['started_at'].dt.day, y='duration', data=jan22, ci=None)

"""- on total, middle of this month has mostly more user
- on average, there is a balance distrubition except for anomaly at 1st January

### Day of The Week
"""

sns.countplot(x=jan22['started_at'].dt.dayofweek, data=jan22)

sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=sum, data=jan22, ci=None)

sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=np.median, data=jan22, ci=None)

"""### Which hour"""

sns.countplot(x=jan22['started_at'].dt.hour, data=jan22)

"""- most of users are during working/school hours"""

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', data=jan22, estimator=sum, ci=None)

sns.barplot(x=jan22['started_at'].dt.hour, y='duration', data=jan22, ci=None)

"""- total of duration is similar to number of count
- average of duration is uniform, except anomaly at 01.00 AM

### Anomaly
"""

#Let's take a look at the Anomaly!
jan22[jan22['started_at'].dt.hour==1].describe()

jan22[jan22['duration']==1756266.0]

"""- there is a user that ride at 20 days starting at 1 January until 21 January (wow!) starting from 1 AM

## Station Name

### Most Popular Count
"""

plt.figure(figsize=(25,8))
sns.countplot(x='start_station_name', data=jan22, color='b',
              order=jan22['start_station_name'].value_counts().iloc[:10].index)

plt.figure(figsize=(25,8))
sns.countplot(x='end_station_name', data=jan22, color='grey',
              order=jan22['end_station_name'].value_counts().iloc[:10].index)

"""- rockwell, campbell, n green, clark, milwaukee ave, clinton, damen ave. 9 out of 10 most popular starting point station also is one of the most popular destination spot.
- it means the most popular station is cathering toward industry or academic spot (for transit)

### Most Popular Duration
"""

order_start10 = jan22.groupby('start_station_name')['duration'].sum().nlargest(10)
order_start10

plt.figure(figsize=(25,8))
sns.barplot(x='start_station_name', y='duration', hue='member_casual', data=jan22, estimator=sum, order=order_start10.index, ci=None)

order_end10 = jan22.groupby('end_station_name')['duration'].sum().nlargest(10)
order_end10

plt.figure(figsize=(25,8))
sns.barplot(x='end_station_name', y='duration', hue='member_casual', data=jan22, estimator=sum, order=order_end10.index, ci=None)

"""#### Most Popular Member Station"""

member_start10 = jan22[jan22['member_casual']=='member'].groupby('start_station_name')['duration'].sum().nlargest(10)
member_start10

member_end10 = jan22[jan22['member_casual']=='member'].groupby('end_station_name')['duration'].sum().nlargest(10)
member_end10

plt.figure(figsize=(25,8))
sns.barplot(x='start_station_name', y='duration', data=jan22[jan22['member_casual']=='member'], estimator=sum, color='gold', order=member_start10.index, ci=None)

plt.figure(figsize=(25,8))
sns.barplot(x='end_station_name', y='duration', data=jan22[jan22['member_casual']=='member'], estimator=sum, color='gold', order=member_end10.index, ci=None)

"""#### Most Popular Casual Station"""

casual_start10 = jan22[jan22['member_casual']=='casual'].groupby('start_station_name')['duration'].sum().nlargest(10)
casual_start10

plt.figure(figsize=(25,8))
sns.barplot(x='start_station_name', y='duration', data=jan22[jan22['member_casual']=='casual'], estimator=sum, order=casual_start10.index, color='silver', ci=None)

"""### Least Popular Count"""

plt.figure(figsize=(25,8))
sns.countplot(x='start_station_name', data=jan22, color='blue',
              order=jan22['start_station_name'].value_counts().sort_values(ascending=True).iloc[:10].index)

plt.figure(figsize=(25,8))
sns.countplot(x='end_station_name', data=jan22, color='grey',
              order=jan22['end_station_name'].value_counts().sort_values(ascending=True).iloc[:10].index)

"""- all of the least popular station only has 1 user this month
- either these are outlier or user tend to use station in other street within the same area

### Top 10 Popular
"""

#Top10
top10_start = jan22['start_station_name'].value_counts().iloc[:10].index
top10_end = jan22['end_station_name'].value_counts().iloc[:10].index
print(top10_start)
print(top10_end)

plt.figure(figsize=(25,8))
sns.barplot(x='start_station_name', y='duration', hue='member_casual', data=jan22[jan22['start_station_name'].isin(top10_start)], estimator=sum, ci=None)

plt.figure(figsize=(25,8))
sns.barplot(x='end_station_name', y='duration', hue='member_casual', data=jan22[jan22['end_station_name'].isin(top10_end)], estimator=sum, ci=None)

"""# Data Visualization

## Ratio of Membership and Casual User
"""

fig, axes = plt.subplots(2, 1, figsize=(5,7))
ax0 = sns.countplot(x=jan22['member_casual'].sort_values(ascending=False), data=jan22, ax=axes[0])
ax1 = sns.barplot(x=jan22['member_casual'].sort_values(ascending=False), y='duration', estimator=sum, data=jan22, ci=None, ax=axes[1])
ax0.set_title('Count of Member and\nCasual User in January 2022', fontweight='bold')
ax0.bar_label(ax0.containers[0])
ax1.set_title('Total Duration of Member and\nCasual User in January 2022', fontweight='bold')
ax1.bar_label(ax1.containers[0])
ax1.set_ylabel('duration (s)')                                                                                                                                
plt.tight_layout()

"""- We can see at January 2022, most of the rides frequency is from Member user
- Most of the user duration also mostly from member user
"""

ax0 = sns.countplot(x='rideable_type', hue=jan22['member_casual'].sort_values(ascending=False), data=jan22)
ax0.set_title('Count of Rideable Type\nby User Category', fontweight='bold')
for bars in ax0.containers:
        ax0.bar_label(bars)
plt.legend(title='User Category', title_fontsize=9, loc='center right', bbox_to_anchor=(1, 0.4, 0.25, 1), fontsize=9)

"""- We can see docked bike is reserved for casual user

## Is Docked Bike Worth Keeping?
"""

fig, axes = plt.subplots(2, 1, figsize=(10,10))
ax0 = sns.barplot(x='rideable_type', y='duration', data=jan22, estimator=sum, ci=None, ax=axes[0])
ax1 = sns.barplot(x='rideable_type', y='duration', data=jan22, estimator=np.median, ci=None, ax=axes[1])
ax0.set_title('Total Duration (s)', fontweight='bold')
for bars in ax0.containers:
        ax0.bar_label(bars)
ax1.set_title('Median Duration (s)', fontweight='bold')
for bars in ax1.containers:
        ax1.bar_label(bars)

"""- Despite the low count of use in Janury, it's still contributing quite decent in the total duration
- Docked bike user have much higher duration per user than other rideable type, which has great potential compared to other type

## Difference Between Casual and Member User
"""

fig, axes = plt.subplots(2, 1, figsize=(13,10))
ax0 = sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='member'], 
                  ax=axes[0], color='C0', ci=None)
ax1 = sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='casual'], 
            ax=axes[1], color='C1', ci=None)
ax0.set_title('Total Duration per Dayweek of Member User', fontweight='bold')
ax0.set_xlabel('Day of The Week')
ax0.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])
ax1.set_title('Total Duration per Dayweek of Casual User', fontweight='bold')
ax1.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])
ax1.set_xlabel('Day of The Week')

"""- Member user has high uses on weekdays
- Casual user has irregular pattern but the highest peak is during weekend
"""

fig, axes = plt.subplots(2, 1, figsize=(13,10))
ax0 = sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=np.median, data=jan22[jan22['member_casual']=='member'],
            ax=axes[0], color='C0', ci=None)
ax0.set_title('Median Duration per Dayweek of Member User')
ax0.set_xlabel('Day of The Week')
ax0.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])
ax1 = sns.barplot(x=jan22['started_at'].dt.dayofweek, y='duration', estimator=np.median, data=jan22[jan22['member_casual']=='casual'],
            ax=axes[1], color='C1', ci=None)
ax1.set_xlabel('Day of The Week')
ax1.set_title('Median Duration per Dayweek of Casual User')
ax1.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])

"""- Overall casual user has higher duration per user than member user, implying that casual user use it other than daily necessities
- Casual user also has higher median during weekend, rather than member user who have uniform distribution thourghout the week
- Based on these graphs, are the majority of the member user in working force and students, and casual user are mostly regular citizens or tourists went to sightseeing? Let's find out further!
"""

fig, axes = plt.subplots(2, 1, figsize=(25,8))
ax0 = sns.barplot(x='start_station_name', y='duration', data=jan22[jan22['member_casual']=='member'], estimator=sum, color='C0', order=member_start10.index,
                  ax=axes[0], ci=None)
ax1 = sns.barplot(x='start_station_name', y='duration', data=jan22[jan22['member_casual']=='casual'], estimator=sum, color='C1', order=casual_start10.index,
                  ax=axes[1], ci=None)
ax0.set_title('Most Popular Start Station Member User', fontsize=16)
ax0.set_xticklabels(ax0.get_xticklabels(), rotation=10, ha="right", fontsize=12)
ax1.set_title('Most Popular Start Station Casual User', fontsize=16)
ax1.set_xticklabels(ax1.get_xticklabels(), rotation=10, ha="right", fontsize=12)
plt.tight_layout()
plt.show()

"""- We can see most of the popular station from member user are residential and metropolitan area for cafe, office, clothing shop, etc
- We can see most of the popular station from casual user are tourist area like park, aquarium, seaside, etc
- Much higher peak-valley of data on Casual user compared to Member user graph, implying Member users have more uniform distribution throughout the station (usually for commuting work and school)
- These graphs support the hypothesis which most of the casual user are reguler citizen for relaxation and tourists, and some of them are future potential member

## What This Mean Next?
"""

fig = plt.figure(figsize=(5,5),dpi=144)
ax1 = fig.add_subplot(121)
ax2 = fig.add_subplot(122)
ax1.pie(jan22['member_casual'].value_counts().values, autopct='%.0f%%', textprops={'fontsize': 6, 'weight':'bold'})
ax1.set_title('Count of Member and \nCasual User', fontsize=9)
ax2.pie(jan22.groupby('member_casual')['duration'].sum().sort_values(ascending=False).values, autopct='%.0f%%', textprops={'fontsize': 6, 'weight':'bold'})
ax2.set_title('Total Duration of Member and \nCasual User', fontsize=9)
plt.tight_layout()
plt.legend(labels=jan22['member_casual'].value_counts().index, title='User Category', title_fontsize=6, loc='center right', bbox_to_anchor=(1, 0.4, 0.3, 1), fontsize=6)
plt.show()

"""- Despite only contributing only 18% in the number of count ride frequency, casual user manage to contribute 31% of total duration in Jaunary 2022"""

fig, axes = plt.subplots(2, 1, figsize=(15,8))
ax0 = sns.barplot(x=jan22['started_at'].dt.day, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='member'], color='C0', ax=axes[0], ci=None)
ax1 = sns.barplot(x=jan22['started_at'].dt.day, y='duration', estimator=sum, data=jan22[jan22['member_casual']=='casual'], color='C1', ax=axes[1], ci=None)
ax0.set_title('Total Duration Daily of Member User\nin January 2022', fontweight='bold')
ax0.set_xlabel('Date')
ax1.set_title('Total Duration Daily of Casual User\nin January 2022', fontweight='bold')
ax1.set_xlabel('Date')
plt.tight_layout()

"""- Despite the high potential, casual user is hard to predict
- We must cater the high potential casual user into joining membership

#### Suggestion

Our focus shuold be prioritized on Casual user, since most of the Member user started as Casual user. We knew Casual user is mostly at the place for sightseeing, so they are our main target!
"""

plt.figure(figsize=(25,5))
ax0 = sns.barplot(x='start_station_name', y='duration', data=jan22[jan22['member_casual']=='casual'], estimator=sum, color='C1', order=casual_start10.index,
                  ci=None)
ax0.set_title('Most Popular Start Station Casual User', fontsize=16, fontweight='bold')
ax0.set_xticklabels(ax0.get_xticklabels(), rotation=10, ha="right", fontsize=12)
plt.show()

casual10 = casual_start10.to_frame().reset_index()

group = []
for i in casual10.index:
  if (i==0) or (i==1):
    group.append('Top 2')
  else:
    group.append('Other')

group

casual10['group'] = group

plt.figure(figsize=(2,2),dpi=144)
plt.pie(casual10.groupby('group')['duration'].sum(), autopct='%.0f%%', textprops={'fontsize': 6, 'weight':'bold'})
plt.legend(labels=casual10['group'].value_counts().index, title='Station Category', title_fontsize=6, loc='center right', bbox_to_anchor=(1, 0.4, 0.4, 1), fontsize=6)
plt.title('Distribution of Top 10 Most Popular Station\nAmong Casual User', fontsize=9)

"""The distribution among Casual user in the Top 10 Most Popular Station is not equal. Two of the most popular spot raking at 49% total duration alone. We can focus on improving the facility among the other 8, here's my recommendation:
- Coordinating with officials in the respected area to have a bike-friendly road to popular spot (focus the top 10 first)
- Prepare a promo or event during weekend and holiday among the popular spot for bike user

"""